{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "fCwikvrICxrg"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torchvision\n",
        "trans=torchvision.transforms.Compose(\n",
        "    [torchvision.transforms.PILToTensor(),\n",
        "     torchvision.transforms.ConvertImageDtype(torch.float)])\n",
        "train_data_transformed = torchvision.datasets.FashionMNIST(\n",
        "    root=\"/22961\", train=True, download=True,\n",
        "    transform=trans)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tWjyvPegDien",
        "outputId": "753a3c95-5edb-45b1-a529-f81fd8a9cb6b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "MyModel(\n",
            "  (linear1): Linear(in_features=784, out_features=10, bias=True)\n",
            "  (activation): ReLU()\n",
            "  (logsoftmax): LogSoftmax(dim=1)\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "from torch import nn\n",
        "\n",
        "class MyModel(torch.nn.Module):\n",
        "\tdef __init__(self):\n",
        "\t\tsuper(MyModel, self).__init__()\n",
        "\n",
        "\t\tself.linear1 = torch.nn.Linear(784, 10)\n",
        "\t\tself.activation = torch.nn.ReLU()\n",
        "\t\t# self.softmax = torch.nn.Softmax()\n",
        "\t\tself.logsoftmax = nn.LogSoftmax(dim=1)\n",
        "\t\n",
        "\tdef forward(self, x):\n",
        "\t\t# 1. X is batch of the samples, as input\n",
        "\t\tx = torch.flatten(x)\n",
        "\n",
        "\t\t# 2. Split input into two tensors with same length (we can assume that the length of X is even)\n",
        "\t\tassert x.shape[0] % 2 == 0\n",
        "\t\tx1, x2 = torch.split(x, 2, dim=1)\n",
        "\t\tassert x1.size() == x2.size()\n",
        "\n",
        "\t\t# 3. Put two tensors into the same aggregation layer (linear, for example)\n",
        "\t\tx1 = self.linear1(x1)\n",
        "\t\tx2 = self.linear1(x2)\n",
        "\n",
        "\t\t# x = self.linear1(x)\n",
        "\n",
        "\t\t# 3. Then put into activation layer\n",
        "\t\tx1 = self.activation(x1)\n",
        "\t\tx2 = self.activation(x2)\n",
        "\n",
        "\n",
        "\t\t# 4. Concatinate two halves to create output Y\n",
        "\t\tx1 = self.softmax(x1)\n",
        "\t\tx2 = self.softmax(x2)\n",
        "\n",
        "\t\tY = torch.cat((x1, x2), 0)\n",
        "\t\t# torch.concat((x1, x2), 0)\n",
        "\t\t\n",
        "\t\treturn Y\n",
        "\n",
        "# model = nn.Sequential(\n",
        "#           nn.Linear(784,10),    #z\n",
        "#           nn.LogSoftmax(dim=1)  #log(y)\n",
        "#           )\n",
        "model = MyModel()\n",
        "print(model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "jnNpPZ9fjmS7"
      },
      "outputs": [],
      "source": [
        "CE_loss=nn.NLLLoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=0.1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "VAu4ORiEoPZl"
      },
      "outputs": [],
      "source": [
        "def iterate_batch():\n",
        "  imgs, labels = next(iter(train_dataloader))\n",
        "  imgs = imgs.flatten(start_dim=1)\n",
        "  optimizer.zero_grad()\n",
        "  y_model=model(imgs)\n",
        "  \n",
        "  loss=CE_loss(y_model,labels)\n",
        "  loss.backward()\n",
        "  optimizer.step()\n",
        "  \n",
        "  predicted_labels = y_model.argmax(dim=1)\n",
        "  acc = (predicted_labels == labels).sum()/len(labels)\n",
        "  return loss.detach(), acc.detach()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZT5QW3tak2jo",
        "outputId": "f5ae8e6d-6aa2-4f1f-c6c1-b6d5dda4465d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "235"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from torch.utils.data import DataLoader\n",
        "train_dataloader = DataLoader(\n",
        "    train_data_transformed, batch_size=256, shuffle=True)\n",
        "len(train_dataloader) #num of batches in epoch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DcB5x44duIP7",
        "outputId": "cc645b65-27c1-445e-bbe4-eb35ab8f82e7"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/235 [00:10<?, ?it/s]\n"
          ]
        },
        {
          "ename": "ValueError",
          "evalue": "too many values to unpack (expected 2)",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_21936/1572006782.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mbatch_acc\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m     \u001b[0mbatch_loss\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_acc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0miterate_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_21936/1113522171.py\u001b[0m in \u001b[0;36miterate_batch\u001b[1;34m()\u001b[0m\n\u001b[0;32m      3\u001b[0m   \u001b[0mimgs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mimgs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstart_dim\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m   \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m   \u001b[0my_model\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimgs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m   \u001b[0mloss\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mCE_loss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_model\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1102\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1103\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_21936/2857704197.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     16\u001b[0m                 \u001b[1;31m# 2. Split input into two tensors with same length (we can assume that the length of X is even)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m                 \u001b[1;32massert\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;36m2\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 18\u001b[1;33m                 \u001b[0mx1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     19\u001b[0m                 \u001b[1;32massert\u001b[0m \u001b[0mx1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mx2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;31mValueError\u001b[0m: too many values to unpack (expected 2)"
          ]
        }
      ],
      "source": [
        "from tqdm import tqdm\n",
        "batches=len(train_dataloader)\n",
        "batch_loss=torch.zeros(batches)\n",
        "batch_acc=torch.zeros(batches)\n",
        "for idx in tqdm(range(batches)):\n",
        "    batch_loss[idx], batch_acc[idx] = iterate_batch()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "QHmThchnvdo5",
        "outputId": "63b1c993-066a-4eab-b599-712b0c5946a0"
      },
      "outputs": [],
      "source": [
        "from matplotlib import pyplot as plt\n",
        "plt.figure(figsize=(12,4))\n",
        "plt.subplot(1,2,1)\n",
        "plt.plot(range(batches),batch_loss);\n",
        "plt.title(\"CE loss\");\n",
        "plt.xlabel(\"Batch Number\");\n",
        "plt.subplot(1,2,2)\n",
        "plt.plot(range(batches),batch_acc);\n",
        "plt.title(\"Accuracy\");\n",
        "plt.xlabel(\"Batch Number\");"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "authorship_tag": "ABX9TyPpXi8MWMKD5eUhqziJY/CA",
      "include_colab_link": true,
      "name": "22961_2_2_4_Single_Layer_Training_PyTorch",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
