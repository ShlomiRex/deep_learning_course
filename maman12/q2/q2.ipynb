{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import sklearn.datasets as skds\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision\n",
    "from torch import nn\n",
    "import numpy\n",
    "import pandas\n",
    "from typing import Optional\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DropNorm(nn.Module):\n",
    "\tdef __init__(self, size_in, size_out):\n",
    "\t\tsuper().__init__()\n",
    "\n",
    "\t\tself.size_in, self.size_out = size_in, size_out\n",
    "\n",
    "\t\tself.weights = nn.Parameter(torch.Tensor(size_out, size_in))  # nn.Parameter is a Tensor that's a module parameter.\n",
    "\t\tself.bias = nn.Parameter(torch.Tensor(size_out))\n",
    "\n",
    "\t\tself.linear1 = nn.Linear(size_in, size_out)\n",
    "\t\tself.activation = nn.ReLU(inplace=True) # inplace = don't use extra memory\n",
    "\n",
    "\t\tself.drop_probability = 0.5  # We can take as argument but this question doesn't requires it.\n",
    "\t\t\n",
    "\t\n",
    "\tdef forward(self, x):\n",
    "\t\t\n",
    "\t\tpass"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "491bb19b02bca4120e598d98c213a4bec2319d7b10161d80e88d4a71a12afc06"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
