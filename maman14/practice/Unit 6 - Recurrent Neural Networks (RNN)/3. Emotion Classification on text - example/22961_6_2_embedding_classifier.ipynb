{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "22961_6_2_Embedding_Classifier",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPD7heSeqUDkL+zX8QvRuD3",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "a5595ee985724516bdb1e20af4d1d63e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_11f5dd30b65845c7952d1e1c0ec9c48a",
              "IPY_MODEL_d6ff9bd827cc4578a5218e72ce8ab7a9",
              "IPY_MODEL_024470ee65974dd980be0187df5f7022"
            ],
            "layout": "IPY_MODEL_c12ce806f27841c4ab20d92967de5360"
          }
        },
        "11f5dd30b65845c7952d1e1c0ec9c48a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_06987b4f013e4a039dff4b9f14aa118c",
            "placeholder": "​",
            "style": "IPY_MODEL_8bd3b415301b474ea966b972ca132084",
            "value": "100%"
          }
        },
        "d6ff9bd827cc4578a5218e72ce8ab7a9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_92988cf428b54e1998684e7f7023b10d",
            "max": 3,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_5dbb041a9e2e49c1bf07cd8406dd6477",
            "value": 3
          }
        },
        "024470ee65974dd980be0187df5f7022": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bc064abcb6bd4c2fbb89258f10c317f3",
            "placeholder": "​",
            "style": "IPY_MODEL_1a29b3e19a704694ab24a50774fa48e4",
            "value": " 3/3 [00:00&lt;00:00, 46.13it/s]"
          }
        },
        "c12ce806f27841c4ab20d92967de5360": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "06987b4f013e4a039dff4b9f14aa118c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8bd3b415301b474ea966b972ca132084": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "92988cf428b54e1998684e7f7023b10d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5dbb041a9e2e49c1bf07cd8406dd6477": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "bc064abcb6bd4c2fbb89258f10c317f3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1a29b3e19a704694ab24a50774fa48e4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/gist/22961-Deep-learning/27700ad4f979c1760672619a577cc209/22961_6_2_embedding_classifier.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install datasets"
      ],
      "metadata": {
        "id": "ypZSD5zEWlqU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "IHn3aU9ykTjM",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 190,
          "referenced_widgets": [
            "a5595ee985724516bdb1e20af4d1d63e",
            "11f5dd30b65845c7952d1e1c0ec9c48a",
            "d6ff9bd827cc4578a5218e72ce8ab7a9",
            "024470ee65974dd980be0187df5f7022",
            "c12ce806f27841c4ab20d92967de5360",
            "06987b4f013e4a039dff4b9f14aa118c",
            "8bd3b415301b474ea966b972ca132084",
            "92988cf428b54e1998684e7f7023b10d",
            "5dbb041a9e2e49c1bf07cd8406dd6477",
            "bc064abcb6bd4c2fbb89258f10c317f3",
            "1a29b3e19a704694ab24a50774fa48e4"
          ]
        },
        "outputId": "036ed555-480c-45a4-d283-4559a625f730"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Reusing dataset glue (/root/.cache/huggingface/datasets/glue/sst2/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/3 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a5595ee985724516bdb1e20af4d1d63e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "contains no wit , only labored gags \n",
            "that loves its characters and communicates something rather beautiful about human nature \n",
            "tensor([2924,   61,  330,    2,   89, 1993,  549])\n",
            "tensor([  10, 1792,   17,   54,    4, 6088,   96,  186,  265,   34,  178,  627])\n",
            "tensor(0)\n",
            "tensor(1)\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "import datasets as ds\n",
        "from pprint import pprint\n",
        "from tqdm import tqdm\n",
        "\n",
        "dataset = ds.load_dataset(\"glue\", \"sst2\")\n",
        "\n",
        "sentence_list=dataset[\"train\"][\"sentence\"]\n",
        "labels_list=dataset[\"train\"][\"label\"]\n",
        "tokenize = lambda x: x.split()\n",
        "tokenized=list(map(tokenize,sentence_list))\n",
        "\n",
        "from torchtext.vocab import build_vocab_from_iterator\n",
        "vocab=build_vocab_from_iterator(tokenized, specials=[\"<UNK>\"],min_freq=5)\n",
        "vocab.set_default_index(1)\n",
        "\n",
        "func = lambda x: torch.tensor(vocab(x))\n",
        "integer_tokens=list(map(func,tokenized))\n",
        "label_tensors=list(map(torch.tensor,labels_list))\n",
        "print(*sentence_list[1:3],sep=\"\\n\")\n",
        "print(*integer_tokens[1:3],sep=\"\\n\")\n",
        "print(*label_tensors[1:3],sep=\"\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_split=len(integer_tokens)*8//10\n",
        "train_tokens=integer_tokens[:test_split]\n",
        "train_labels=label_tensors[:test_split]\n",
        "test_tokens=integer_tokens[test_split:]\n",
        "test_labels=label_tensors[test_split:]"
      ],
      "metadata": {
        "id": "jv3YJJUsR6-M"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ClassificationHead(nn.Module):\n",
        "    def __init__(self, in_features):\n",
        "        super().__init__()\n",
        "        self.linear = nn.Linear(in_features, 2)\n",
        "        self.logsoftmax = nn.LogSoftmax(dim=0)\n",
        "\n",
        "    def forward(self, feature_extractor_output):\n",
        "        class_scores= self.linear(feature_extractor_output)\n",
        "        logprobs    = self.logsoftmax(class_scores)\n",
        "        return logprobs"
      ],
      "metadata": {
        "id": "wYZwVkKtW32c"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class FeatureExtractor_1(nn.Module):\n",
        "    def __init__(self, embed_dim):\n",
        "        super().__init__()\n",
        "        self.embedding = nn.Embedding(len(vocab),embed_dim)\n",
        "\n",
        "    def forward(self, sentence_tokens):\n",
        "        embedded    = self.embedding(sentence_tokens)\n",
        "        return embedded"
      ],
      "metadata": {
        "id": "cXLulARiYRVm"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "example_sentence=sentence_list[1]"
      ],
      "metadata": {
        "id": "nNZ4AeCSbtuF"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(example_sentence)\n",
        "\n",
        "preprocess= lambda x: torch.tensor(vocab(x.split()))\n",
        "tokens=preprocess(example_sentence)\n",
        "print(tokens)\n",
        "\n",
        "extractor=FeatureExtractor_1(2)\n",
        "features=extractor(tokens)\n",
        "print(features,features.size(),sep=\"\\n\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RsI5CYZPaDMy",
        "outputId": "1b11dc7a-7707-461d-a8e1-7f1a4af64549"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "contains no wit , only labored gags \n",
            "tensor([2924,   61,  330,    2,   89, 1993,  549])\n",
            "tensor([[ 1.6337,  0.7351],\n",
            "        [-0.9232,  0.3840],\n",
            "        [ 0.5395,  0.2960],\n",
            "        [-0.5276,  1.6171],\n",
            "        [ 0.2901,  2.6462],\n",
            "        [ 1.5971, -0.2344],\n",
            "        [-0.3403,  0.2870]], grad_fn=<EmbeddingBackward0>)\n",
            "torch.Size([7, 2])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class FeatureExtractor(nn.Module):\n",
        "    def __init__(self, embed_dim):\n",
        "        super().__init__()\n",
        "        self.embedding = nn.Embedding(len(vocab),embed_dim)\n",
        "\n",
        "    def forward(self, sentence_tokens):\n",
        "        embedded    = self.embedding(sentence_tokens)\n",
        "        feature_extractor_output = embedded.sum(dim=0)    #\n",
        "        return feature_extractor_output"
      ],
      "metadata": {
        "id": "lzUs8qBZdzD_"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "extractor=FeatureExtractor(2)\n",
        "features=extractor(tokens)\n",
        "print(features,features.size(),sep=\"\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z8x3upTXd9Bm",
        "outputId": "85c9c862-02af-4d6c-8678-c2a647c41513"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([ 0.9963, -1.0662], grad_fn=<SumBackward1>)\n",
            "torch.Size([2])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class EmbedSumClassify(nn.Module):\n",
        "    def __init__(self, embed_dim):\n",
        "        super().__init__()\n",
        "        self.extractor  = FeatureExtractor(embed_dim)\n",
        "        self.classifier = ClassificationHead(embed_dim)\n",
        "\n",
        "    def forward(self, sentence_tokens):\n",
        "        extracted_features = self.extractor(sentence_tokens)\n",
        "        logprobs    = self.classifier(extracted_features)\n",
        "        return logprobs"
      ],
      "metadata": {
        "id": "dp4ucjtnDpQx"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model=EmbedSumClassify(2)\n",
        "print(model(tokens))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HO33gDxWGr_l",
        "outputId": "ac2c7b89-eb31-4e00-8cbe-3eb4fc2bb1e9"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([-0.0870, -2.4856], grad_fn=<LogSoftmaxBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def iterate_one_sentence(tokens,label,train_flag):\n",
        "  tokens=tokens\n",
        "  if train_flag:\n",
        "    model.train()  \n",
        "    optimizer.zero_grad()\n",
        "    y_model=model(tokens)\n",
        "    loss= -y_model[label] #CE loss\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "  else:\n",
        "    model.eval()\n",
        "    y_model=model(tokens)\n",
        "    model.train()\n",
        "  with torch.no_grad():\n",
        "    predicted_labels = y_model.argmax(dim=0)\n",
        "    success = (predicted_labels == label)\n",
        "  return success\n",
        "\n",
        "def train_one_epoch():\n",
        "  correct_predictions=torch.tensor([0.])\n",
        "  for tokens,label in tqdm(zip(train_tokens,train_labels),total=len(train_tokens)):\n",
        "    correct_predictions += iterate_one_sentence(tokens,label,train_flag=True)\n",
        "  acc=correct_predictions/len(train_tokens)\n",
        "  print(\"\\n\",acc)\n",
        "  return acc\n",
        "\n",
        "def test_model():\n",
        "  test_correct_predictions=torch.tensor([0.])\n",
        "  for tokens,label in tqdm(zip(test_tokens,test_labels),total=len(test_tokens)):\n",
        "    test_correct_predictions += iterate_one_sentence(tokens,label,train_flag=False)\n",
        "  test_acc=test_correct_predictions/len(test_tokens)\n",
        "  return test_acc"
      ],
      "metadata": {
        "id": "dzwSlR8DKZsi"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model=EmbedSumClassify(5)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.05)\n",
        "\n",
        "acc=train_one_epoch()\n",
        "test_acc=test_model()"
      ],
      "metadata": {
        "id": "CMc4qzRhKhcM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "239e1678-51b4-4678-8657-bcba79ece70c"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 53879/53879 [01:48<00:00, 496.76it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " tensor([0.7621])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 13470/13470 [00:02<00:00, 5904.77it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#check on random labels\n",
        "test_correct_predictions=torch.tensor([0.])\n",
        "random_labels=torch.rand(len(test_tokens))<0.5\n",
        "for tokens,label in tqdm(zip(test_tokens,random_labels),total=len(test_tokens)):\n",
        "  test_correct_predictions += iterate_one_sentence(tokens,label,train_flag=False)\n",
        "rand_acc=test_correct_predictions/len(test_tokens)"
      ],
      "metadata": {
        "id": "G0i0twdSSvuA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "28e4739d-9870-4dcc-d456-8b9077133885"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 13470/13470 [00:02<00:00, 5728.82it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(acc,test_acc,rand_acc, sep=\"\\n\")"
      ],
      "metadata": {
        "id": "aWte36PXPVbB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "11d3b3b0-57b9-4e8c-cbc7-f79f54d84154"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([0.7621])\n",
            "tensor([0.8223])\n",
            "tensor([0.5004])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "preprocess = lambda x: torch.tensor(vocab(x.split()))\n",
        "example_sentences=[\"very good , not bad\",\n",
        "                   \"very bad , not good\"]\n",
        "with torch.no_grad():                   \n",
        "  for sent in example_sentences:\n",
        "    print(preprocess(sent))\n",
        "    print(torch.exp(model(preprocess(sent))))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-Ok0CNxFVAr4",
        "outputId": "a26c708b-5228-49d9-a008-c676c6c8eae1"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([77, 46,  2, 33, 74])\n",
            "tensor([9.9984e-01, 1.6109e-04])\n",
            "tensor([77, 74,  2, 33, 46])\n",
            "tensor([9.9984e-01, 1.6109e-04])\n"
          ]
        }
      ]
    }
  ]
}